//gets the new block from the file
bool FTokenizer::get_new_block()
{
    bool debug = true;  //bool value for turning debugging on/off

    char * buffer = new char[MAX_BLOCK];

    // read data as a block:
    _f.read(buffer, MAX_BLOCK - 1);
    buffer[_f.gcount()] = '\0';

    //for debugging - grabs one block
    if(debug) {
        while(buffer[_pos+1] != '\0' && _pos <= MAX_BLOCK)
        {
            cout << buffer[_pos];
            _pos++;
        }
        cout << endl;
        _pos = 0;  //reset position
    }

//    cout << "count: " << _f.gcount() << endl;
    if(_f.gcount() > 0)
    {
        _stk.set_string(buffer);
        delete[] buffer;

        return _f.gcount() > 0;

    }


    //for debugging - prints stokenized version of block
    if(debug) {
        Token t;
        // The all too familiar golden while loop:
        _stk >> t;
        while(_stk.more())
        {
            // process token here...
            cout << setw(10) << t.type_string() << setw(10) << t << endl;

            t = Token();
            _stk >> t;
        }
    }

    return false;

}